#!/usr/bin/env python3
"""
æ¨¡å‹è¯„ä¼°è„šæœ¬
è¯„ä¼°å›¾åƒç›¸ä¼¼åº¦æ¨¡å‹çš„Precision@5ã€Recall@5ã€mAPæŒ‡æ ‡
æ”¯æŒå€™é€‰é›†å›¾ç‰‡ç‰¹å¾æå–å’Œå‘é‡æ•°æ®åº“å­˜å‚¨
"""

import os
import json
import numpy as np
import argparse
from pathlib import Path

# å¯¼å…¥ç°æœ‰çš„æ¨¡å—
from feature import FeatureExtractor
from vector_db import MilvusManager, batch_insert_images

def calculate_precision_recall_at_k(query_results, relevant_images, k=5):
    """
    è®¡ç®—Precision@kå’ŒRecall@k
    
    å‚æ•°:
        query_results: æŸ¥è¯¢ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«image_path
        relevant_images: ç›¸å…³å›¾åƒåˆ—è¡¨
        k: è¯„ä¼°çš„kå€¼
        
    è¿”å›:
        precision_at_k: Precision@k
        recall_at_k: Recall@k
    """
    # æå–å‰kä¸ªç»“æœçš„å›¾åƒè·¯å¾„ï¼ˆåªå–æ–‡ä»¶åéƒ¨åˆ†è¿›è¡Œæ¯”è¾ƒï¼‰
    retrieved_images = [os.path.basename(result['image_path']) for result in query_results[:k]]
    relevant_images = [os.path.basename(img) for img in relevant_images]
    
    # è®¡ç®—TPï¼ˆçœŸé˜³æ€§ï¼‰
    tp = len(set(retrieved_images) & set(relevant_images))
    
    # è®¡ç®—Precision@k
    precision_at_k = tp / k if k > 0 else 0
    
    # è®¡ç®—Recall@k
    recall_at_k = tp / len(relevant_images) if len(relevant_images) > 0 else 0
    
    return precision_at_k, recall_at_k

def calculate_ap(query_results, relevant_images, max_k=5):
    """
    è®¡ç®—å¹³å‡ç²¾åº¦(AP)
    
    å‚æ•°:
        query_results: æŸ¥è¯¢ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«image_path
        relevant_images: ç›¸å…³å›¾åƒåˆ—è¡¨
        max_k: æœ€å¤§è¯„ä¼°çš„kå€¼
        
    è¿”å›:
        ap: å¹³å‡ç²¾åº¦å€¼
    """
    if not relevant_images:
        return 0.0
    
    retrieved_images = [os.path.basename(result['image_path']) for result in query_results[:max_k]]
    relevant_images = [os.path.basename(img) for img in relevant_images]
    
    relevant_set = set(relevant_images)
    ap = 0.0
    tp_count = 0
    
    for i, img in enumerate(retrieved_images):
        if img in relevant_set:
            tp_count += 1
            precision_at_i = tp_count / (i + 1)
            ap += precision_at_i
    
    # ä½¿ç”¨å®é™…æ‰¾å‡ºçš„ç›¸å…³é¡¹æ•°é‡ä½œä¸ºåˆ†æ¯ï¼ˆæ ‡å‡†APè®¡ç®—æ–¹æ³•ï¼‰
    if tp_count == 0:
        return 0.0
    return ap / tp_count

def evaluate_model(model_name, annotations_path, image_dir, device='auto'):
    """
    è¯„ä¼°æŒ‡å®šæ¨¡å‹
    
    å‚æ•°:
        model_name: è¦è¯„ä¼°çš„æ¨¡å‹åç§°
        annotations_path: æ ‡æ³¨æ–‡ä»¶è·¯å¾„
        image_dir: å›¾åƒç›®å½•è·¯å¾„
        device: è¿è¡Œè®¾å¤‡
        
    è¿”å›:
        results: è¯„ä¼°ç»“æœå­—å…¸
    """
    print(f"\n{'='*60}")
    print(f"ğŸ” å¼€å§‹è¯„ä¼°æ¨¡å‹: {model_name}")
    print(f"{'='*60}")
    
    # 1. åŠ è½½ç‰¹å¾æå–å™¨
    print(f"\nğŸ“¦ åŠ è½½ç‰¹å¾æå–å™¨...")
    feature_extractor = FeatureExtractor(model_name=model_name, device=device)
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ: {feature_extractor.get_model_info()}")
    
    # 2. åŠ è½½æ ‡æ³¨æ–‡ä»¶
    print(f"\nğŸ“„ åŠ è½½æ ‡æ³¨æ–‡ä»¶...")
    with open(annotations_path, 'r', encoding='utf-8') as f:
        annotations = json.load(f)
    print(f"âœ… åŠ è½½å®Œæˆ: {len(annotations)}ä¸ªæŸ¥è¯¢æ ·æœ¬")
    
    # 3. è¿æ¥å‘é‡æ•°æ®åº“
    print(f"\nğŸ—„ï¸ è¿æ¥å‘é‡æ•°æ®åº“...")
    
    # æ¨¡å‹å¯¹åº”çš„é›†åˆåç§°ï¼ˆä¸init_db.pyä¿æŒä¸€è‡´ï¼‰
    collection_name = f"image_features_{model_name}"
    
    # ä½¿ç”¨Dockerä¸­çš„Milvusï¼ˆä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
    vector_db = MilvusManager(
        host="localhost",
        port=19532,
        collection_name=collection_name,
        dimension=feature_extractor.feature_dim,
        metric_type="COSINE"
    )
    
    # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨ï¼ˆè¯„ä¼°é˜¶æ®µé›†åˆåº”è¯¥å·²ç»å­˜åœ¨ï¼‰
    try:
        from pymilvus import utility
        if not utility.has_collection(collection_name):
            print(f"âŒ é›†åˆä¸å­˜åœ¨: {collection_name}")
            print(f"âš  è¯·å…ˆè¿è¡Œç‰¹å¾æå–åŠŸèƒ½åˆ›å»ºé›†åˆ")
            print(f"   ä½¿ç”¨å‘½ä»¤: python evaluate_model.py --model {model_name} --extract_candidates <å€™é€‰é›†ç›®å½•>")
            return None
        
        print(f"âœ… é›†åˆå­˜åœ¨: {collection_name}")
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥é›†åˆå­˜åœ¨æ€§å¤±è´¥: {e}")
        return None
    
    # åŠ è½½é›†åˆï¼ˆè¯„ä¼°é˜¶æ®µé›†åˆåº”è¯¥å·²ç»å­˜åœ¨ï¼‰
    try:
        # å°è¯•åˆ›å»ºé›†åˆï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        vector_db.create_collection(drop_existing=False)
        
        # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
        try:
            # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
            vector_db.create_index()
            print(f"âœ… ç´¢å¼•å·²å­˜åœ¨æˆ–åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            print(f"   æ£€æŸ¥ç´¢å¼•å­˜åœ¨æ€§æ—¶å‡ºé”™: {e}")
        
        # ç„¶ååŠ è½½é›†åˆ
        vector_db.load_collection()
        print(f"âœ… é›†åˆåŠ è½½æˆåŠŸ")
        print(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼Œé›†åˆåç§°: {collection_name}")
    except Exception as e:
        print(f"âŒ åŠ è½½é›†åˆå¤±è´¥: {e}")
        print(f"âš  å°è¯•ç»§ç»­æ‰§è¡Œï¼Œè·³è¿‡ç´¢å¼•å’ŒåŠ è½½æ­¥éª¤...")
        # ç»§ç»­æ‰§è¡Œï¼Œä¸è¿”å›é”™è¯¯
        print(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼Œé›†åˆåç§°: {collection_name}")
    
    # 4. è¯„ä¼°è¿‡ç¨‹
    print(f"\nğŸ“Š å¼€å§‹è¯„ä¼°...")
    
    total_queries = 0
    total_precision_at_5 = 0.0
    total_recall_at_5 = 0.0
    total_precision_at_10 = 0.0
    total_recall_at_10 = 0.0
    total_ap = 0.0
    
    # åˆå§‹åŒ–ç±»åˆ«æŒ‡æ ‡å­—å…¸
    category_metrics = {}
    
    for i, annotation in enumerate(annotations, 1):
        query_image = annotation['query_image']
        relevant_images = annotation['relevant_images']
        # è·å–ç±»åˆ«ä¿¡æ¯ï¼Œé»˜è®¤ä¸º'unknown'
        category = annotation.get('category', 'unknown')
        
        # è·³è¿‡æ²¡æœ‰ç›¸å…³å›¾åƒçš„æŸ¥è¯¢ï¼ˆæ— æ³•è®¡ç®—æœ‰æ„ä¹‰çš„å¬å›ç‡ï¼‰
        if not relevant_images:
            continue
        
        # æ„å»ºå®Œæ•´çš„æŸ¥è¯¢å›¾åƒè·¯å¾„ï¼ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„image_dirï¼‰
        query_image_path = os.path.join(image_dir, query_image)
        
        if not os.path.exists(query_image_path):
            print(f"âš  è·³è¿‡ä¸å­˜åœ¨çš„æŸ¥è¯¢å›¾åƒ: {query_image}")
            print(f"   å®Œæ•´è·¯å¾„: {query_image_path}")
            continue
        
        try:
            # æå–æŸ¥è¯¢å›¾åƒçš„ç‰¹å¾
            query_features = feature_extractor.extract_features(query_image_path)
            
            # L2å½’ä¸€åŒ–å¤„ç†ï¼ˆç”¨äºä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
            norm = np.linalg.norm(query_features)
            if norm > 0:
                query_features = query_features / norm
            
            # åœ¨å‘é‡æ•°æ®åº“ä¸­æœç´¢å‰10ä¸ªç›¸ä¼¼å›¾åƒ
            search_results = vector_db.search(query_vector=query_features, top_k=10)
            
            if not search_results:
                print(f"âš  æŸ¥è¯¢ {query_image} æ²¡æœ‰è¿”å›ç»“æœ")
                continue
            
            # è®¡ç®—æŒ‡æ ‡
            precision_at_5, recall_at_5 = calculate_precision_recall_at_k(search_results, relevant_images, k=5)
            precision_at_10, recall_at_10 = calculate_precision_recall_at_k(search_results, relevant_images, k=10)
            ap = calculate_ap(search_results, relevant_images, max_k=10)
            
            # ç´¯åŠ æ€»æŒ‡æ ‡
            total_precision_at_5 += precision_at_5
            total_recall_at_5 += recall_at_5
            total_precision_at_10 += precision_at_10
            total_recall_at_10 += recall_at_10
            total_ap += ap
            total_queries += 1  # åªæœ‰æˆåŠŸå®Œæˆè¯„ä¼°çš„æ ·æœ¬æ‰è®¡å…¥
            
            # ç´¯åŠ ç±»åˆ«æŒ‡æ ‡
            if category not in category_metrics:
                category_metrics[category] = {
                    'count': 0,
                    'precision_at_5': 0.0,
                    'recall_at_5': 0.0,
                    'precision_at_10': 0.0,
                    'recall_at_10': 0.0,
                    'ap': 0.0
                }
            
            category_metrics[category]['count'] += 1
            category_metrics[category]['precision_at_5'] += precision_at_5
            category_metrics[category]['recall_at_5'] += recall_at_5
            category_metrics[category]['precision_at_10'] += precision_at_10
            category_metrics[category]['recall_at_10'] += recall_at_10
            category_metrics[category]['ap'] += ap
            
            if i % 50 == 0:
                print(f"  è¿›åº¦: {i}/{len(annotations)} æŸ¥è¯¢å®Œæˆ")
                print(f"  å½“å‰å¹³å‡ - Precision@5: {total_precision_at_5/total_queries:.4f}, Recall@5: {total_recall_at_5/total_queries:.4f}")
                print(f"  å½“å‰å¹³å‡ - Precision@10: {total_precision_at_10/total_queries:.4f}, Recall@10: {total_recall_at_10/total_queries:.4f}")
                print(f"  å½“å‰å¹³å‡ - mAP: {total_ap/total_queries:.4f}")
                
        except Exception as e:
            print(f"âš  å¤„ç†æŸ¥è¯¢ {query_image} æ—¶å‡ºé”™: {e}")
            continue
    
    # 5. è®¡ç®—å¹³å‡æŒ‡æ ‡
    print(f"\n{'='*60}")
    print(f"ğŸ“ˆ è¯„ä¼°ç»“æœ")
    print(f"{'='*60}")
    
    if total_queries == 0:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æŸ¥è¯¢æ ·æœ¬")
        return None
    
    # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å¹³å‡æŒ‡æ ‡
    category_results = {}
    for category, metrics in category_metrics.items():
        count = metrics['count']
        if count > 0:
            category_results[category] = {
                'count': count,
                'precision_at_5': metrics['precision_at_5'] / count,
                'recall_at_5': metrics['recall_at_5'] / count,
                'precision_at_10': metrics['precision_at_10'] / count,
                'recall_at_10': metrics['recall_at_10'] / count,
                'mAP': metrics['ap'] / count
            }
    
    # æ‰“å°æ¯ä¸ªç±»åˆ«çš„è¯„ä¼°ç»“æœ
    if category_results:
        print(f"\n{'='*60}")
        print(f"ğŸ“‹ æŒ‰ç±»åˆ«è¯„ä¼°ç»“æœ")
        print(f"{'='*60}")
        
        for category, result in category_results.items():
            print(f"\nğŸ“Š ç±»åˆ«: {category}")
            print(f"â”œâ”€â”€ è¯„ä¼°æ ·æœ¬æ•°: {result['count']}")
            print(f"â”œâ”€â”€ Precision@5: {result['precision_at_5']:.4f}")
            print(f"â”œâ”€â”€ Recall@5: {result['recall_at_5']:.4f}")
            print(f"â”œâ”€â”€ Precision@10: {result['precision_at_10']:.4f}")
            print(f"â”œâ”€â”€ Recall@10: {result['recall_at_10']:.4f}")
            print(f"â””â”€â”€ mAP: {result['mAP']:.4f}")
    
    # è®¡ç®—æ€»å¹³å‡æŒ‡æ ‡
    avg_precision_at_5 = total_precision_at_5 / total_queries
    avg_recall_at_5 = total_recall_at_5 / total_queries
    avg_precision_at_10 = total_precision_at_10 / total_queries
    avg_recall_at_10 = total_recall_at_10 / total_queries
    mAP = total_ap / total_queries
    
    results = {
        'model_name': model_name,
        'total_queries': total_queries,
        'precision_at_5': avg_precision_at_5,
        'recall_at_5': avg_recall_at_5,
        'precision_at_10': avg_precision_at_10,
        'recall_at_10': avg_recall_at_10,
        'mAP': mAP,
        'category_results': category_results
    }
    
    # æ‰“å°æ€»ç»“æœ
    print(f"\n{'='*60}")
    print(f"ğŸ“Š æ€»è¯„ä¼°ç»“æœ")
    print(f"{'='*60}")
    print(f"æ¨¡å‹åç§°: {model_name}")
    print(f"è¯„ä¼°æ ·æœ¬æ•°: {total_queries}")
    print(f"Precision@5: {avg_precision_at_5:.4f}")
    print(f"Recall@5: {avg_recall_at_5:.4f}")
    print(f"Precision@10: {avg_precision_at_10:.4f}")
    print(f"Recall@10: {avg_recall_at_10:.4f}")
    print(f"mAP: {mAP:.4f}")
    print(f"{'='*60}")
    
    return results

def extract_candidate_features(model_name, candidate_dir, device='auto', overwrite=False, batch_size=32, refresh=False):
    """
    æå–å€™é€‰é›†å›¾ç‰‡ç‰¹å¾å¹¶å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
    
    å‚æ•°:
        model_name: æ¨¡å‹åç§°
        candidate_dir: å€™é€‰é›†å›¾ç‰‡ç›®å½•
        device: è¿è¡Œè®¾å¤‡
        overwrite: æ˜¯å¦è¦†ç›–ç°æœ‰é›†åˆï¼ˆTrue: åˆ é™¤ç°æœ‰é›†åˆå¹¶é‡æ–°åˆ›å»º, False: å¢é‡æ›´æ–°ï¼‰
        batch_size: æ‰¹é‡å¤„ç†å¤§å°
        refresh: æ˜¯å¦åˆ·æ–°ç‰¹å¾ï¼ˆTrue: æ£€æŸ¥å¹¶æ›´æ–°æ–°å›¾ç‰‡çš„ç‰¹å¾, False: ä¸æ‰§è¡Œä»»ä½•æ“ä½œï¼‰
        
    è¿”å›:
        bool: æ˜¯å¦æˆåŠŸ
    """
    # å¦‚æœæœªé…ç½®refreshå‚æ•°ï¼Œåˆ™ä¸é‡æ–°æå–ç‰¹å¾ï¼Œä¹Ÿä¸æ›´æ–°Milvusæ•°æ®åº“
    if not refresh:
        print(f"\n{'='*60}")
        print(f"ğŸ“¸ è·³è¿‡ç‰¹å¾æå–ï¼šæœªé…ç½®refreshå‚æ•°")
        print(f"{'='*60}")
        return True
    import os
    
    print(f"\n{'='*60}")
    print(f"ğŸ“¸ å¼€å§‹æå–å€™é€‰é›†å›¾ç‰‡ç‰¹å¾")
    print(f"æ¨¡å‹: {model_name}")
    print(f"å€™é€‰é›†ç›®å½•: {candidate_dir}")
    print(f"{'='*60}")
    
    # 1. æ£€æŸ¥å€™é€‰é›†ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(candidate_dir):
        print(f"âŒ å€™é€‰é›†ç›®å½•ä¸å­˜åœ¨: {candidate_dir}")
        return False
    
    # 2. åŠ è½½ç‰¹å¾æå–å™¨
    print(f"\nğŸ“¦ åŠ è½½ç‰¹å¾æå–å™¨...")
    try:
        feature_extractor = FeatureExtractor(model_name=model_name, device=device)
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ: {feature_extractor.get_model_info()}")
    except Exception as e:
        print(f"âŒ ç‰¹å¾æå–å™¨åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 3. è¿æ¥å‘é‡æ•°æ®åº“
    print(f"\nğŸ—„ï¸ è¿æ¥å‘é‡æ•°æ®åº“...")
    
    # æ¨¡å‹å¯¹åº”çš„é›†åˆåç§°
    collection_name = f"image_features_{model_name}"
    
    vector_db = MilvusManager(
        host="localhost",
        port=19532,
        collection_name=collection_name,
        dimension=feature_extractor.feature_dim,
        metric_type="COSINE"
    )
    
    # åˆå§‹åŒ–é›†åˆ
    if overwrite:
        print(f"   æ¨¡å¼: è¦†ç›–ç°æœ‰é›†åˆ,å…ˆåˆ é™¤ç°æœ‰é›†åˆå†åˆ›å»ºåŒåç©ºé›†åˆ")
        vector_db.create_collection(drop_existing=True)
        print(f"âœ… åˆ›å»ºé›†åˆæˆåŠŸ: {collection_name}")
    else:
        print(f"   æ¨¡å¼: å¢é‡æ›´æ–°ç°æœ‰é›†åˆ")
        vector_db.create_collection(drop_existing=False)
        print(f"âœ… åˆå§‹åŒ–é›†åˆæˆåŠŸ: {collection_name}")
    
    # æ³¨æ„ï¼šä¸ç«‹å³åŠ è½½é›†åˆï¼Œé¿å…ç´¢å¼•æ£€æŸ¥é—®é¢˜
    # åªæœ‰åœ¨éœ€è¦æœç´¢æ—¶æ‰åŠ è½½é›†åˆï¼Œæ’å…¥æ•°æ®æ—¶ä¸éœ€è¦åŠ è½½é›†åˆ
    print(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼Œé›†åˆåç§°: {collection_name}")
    
    # 4. æ‰«æå€™é€‰é›†å›¾ç‰‡
    print(f"\nğŸ” æ‰«æå€™é€‰é›†å›¾ç‰‡...")
    
    # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp'}
    
    # æ”¶é›†æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    all_candidate_images = []
    for root, dirs, files in os.walk(candidate_dir):
        for file in files:
            if any(file.lower().endswith(ext) for ext in image_extensions):
                all_candidate_images.append(os.path.join(root, file))
    
    if not all_candidate_images:
        print(f"âŒ åœ¨ç›®å½• {candidate_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return False
    
    print(f"âœ… æ‰¾åˆ° {len(all_candidate_images)} å¼ å€™é€‰é›†å›¾ç‰‡")
    
    # è·å–å·²å­˜åœ¨çš„å›¾ç‰‡è·¯å¾„ï¼ˆå¢é‡æ›´æ–°æ¨¡å¼ï¼‰
    existing_images = set()
    if not overwrite:
        try:
            # ä»å‘é‡æ•°æ®åº“è·å–æ‰€æœ‰å·²å­˜åœ¨çš„å›¾ç‰‡è·¯å¾„
            from pymilvus import connections, utility, Collection
            connections.connect(host='localhost', port=19532)
            collection = Collection(collection_name)
            
            # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬pymilvusï¼‰
            has_index = False
            try:
                from pymilvus import utility
                # å°è¯•è·å–ç´¢å¼•ä¿¡æ¯
                index_info = collection.indexes
                if index_info:
                    has_index = True
                    print(f"   âœ… ç´¢å¼•å·²å­˜åœ¨")
                else:
                    has_index = False
            except Exception as e:
                print(f"   æ£€æŸ¥ç´¢å¼•å­˜åœ¨æ€§æ—¶å‡ºé”™: {e}")
                has_index = False
            
            # å¦‚æœç´¢å¼•ä¸å­˜åœ¨ï¼Œåˆ›å»ºç´¢å¼•
            if not has_index:
                print(f"   ç´¢å¼•ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»ºç´¢å¼•...")
                # åˆ›å»ºç´¢å¼•
                index_params = {
                    "index_type": "HNSW",
                    "metric_type": "COSINE",
                    "params": {"M": 16, "efConstruction": 256}
                }
                collection.create_index(field_name="feature_vector", index_params=index_params)
                print(f"   âœ… ç´¢å¼•åˆ›å»ºæˆåŠŸ")
            
            # å°è¯•åŠ è½½é›†åˆ
            try:
                collection.load()
                loaded = True
            except Exception as load_error:
                print(f"   å°è¯•åŠ è½½é›†åˆå¤±è´¥: {load_error}")
                print(f"   ç»§ç»­æ‰§è¡Œï¼Œä½†æ— æ³•è·å–å·²å­˜åœ¨å›¾ç‰‡åˆ—è¡¨")
                loaded = False
            
            # è·å–é›†åˆä¸­çš„å®ä½“æ•°é‡
            collection.flush()
            existing_entity_count = collection.num_entities
            
            # å¦‚æœåŠ è½½æˆåŠŸï¼Œåˆ™æ‰§è¡ŒæŸ¥è¯¢
            if loaded:
                # ä½¿ç”¨æœ‰æ•ˆçš„è¡¨è¾¾å¼ï¼Œé¿å…ç©ºè¡¨è¾¾å¼é”™è¯¯
                expr = "id >= 0"  # åˆæ³•çš„æ¡ä»¶ï¼Œè·å–æ‰€æœ‰è®°å½•
                result = collection.query(expr=expr, output_fields=["image_path"], limit=existing_entity_count + 1000)
                
                for item in result:
                    existing_image_path = item.get("image_path", "")
                    if existing_image_path:
                        # å½’ä¸€åŒ–è·¯å¾„æ ¼å¼ï¼Œç¡®ä¿è·¨å¹³å°ä¸€è‡´æ€§
                        normalized_path = existing_image_path.replace('\\', '/')
                        existing_images.add(normalized_path)
                
                print(f"   å·²å­˜åœ¨ {len(existing_images)} å¼ å›¾ç‰‡çš„ç‰¹å¾")
                
                # é‡Šæ”¾é›†åˆèµ„æº
                collection.release()
            else:
                # å¦‚æœåŠ è½½å¤±è´¥ï¼Œåˆ™å‡è®¾æ²¡æœ‰å·²å­˜åœ¨çš„å›¾ç‰‡
                print(f"   æ— æ³•åŠ è½½é›†åˆï¼Œå‡è®¾æ²¡æœ‰å·²å­˜åœ¨çš„å›¾ç‰‡")
                existing_images = set()
        except Exception as e:
            print(f"   è·å–å·²å­˜åœ¨å›¾ç‰‡åˆ—è¡¨å¤±è´¥: {e}")
            print(f"   ç»§ç»­æ‰§è¡Œå¢é‡æ›´æ–°ï¼Œå‡è®¾æ²¡æœ‰å·²å­˜åœ¨çš„å›¾ç‰‡")
            existing_images = set()
            # ä¸è®¾ç½®overwrite=Trueï¼Œç»§ç»­ä½¿ç”¨å¢é‡æ›´æ–°æ¨¡å¼
    
    # æ‰§è¡Œæ•°æ®åº“ä¸å®é™…å›¾ç‰‡åŒæ­¥ï¼ˆåªåœ¨refreshæ¨¡å¼ä¸‹æ‰§è¡Œï¼‰
    if refresh:
        try:
            # è·å–å½“å‰å®é™…å­˜åœ¨çš„å›¾ç‰‡è·¯å¾„
            current_images = set()
            for image_path in all_candidate_images:
                rel_path = os.path.relpath(image_path, candidate_dir)
                # å½’ä¸€åŒ–è·¯å¾„æ ¼å¼ï¼Œç¡®ä¿è·¨å¹³å°ä¸€è‡´æ€§
                normalized_path = rel_path.replace('\\', '/')
                current_images.add(normalized_path)
            
            # æ‰¾å‡ºæ•°æ®åº“ä¸­å­˜åœ¨ä½†å®é™…ä¸å­˜åœ¨çš„å›¾ç‰‡è·¯å¾„
            removed_images = existing_images - current_images
            
            if removed_images:
                print(f"   å‘ç° {len(removed_images)} å¼ å›¾ç‰‡å·²ä»æœ¬åœ°åˆ é™¤ï¼Œå°†ä»æ•°æ®åº“ä¸­ç§»é™¤å¯¹åº”çš„å‘é‡")
                
                # è¿æ¥åˆ°Milvus
                from pymilvus import connections, utility, Collection
                connections.connect(host='localhost', port=19532)
                collection = Collection(collection_name)
                
                # åŠ è½½é›†åˆåˆ°å†…å­˜ä¸­ï¼ˆåˆ é™¤å‰å¿…é¡»åŠ è½½é›†åˆï¼‰
                collection.load(skip_index_check=True)
                
                # é€ä¸ªåˆ é™¤æ•°æ®åº“ä¸­ä¸å­˜åœ¨çš„å›¾ç‰‡å¯¹åº”çš„å‘é‡
                successfully_deleted = set()
                for image_path in removed_images:
                    print(f"   åˆ é™¤å›¾ç‰‡ {image_path} å¯¹åº”çš„å‘é‡")
                    try:
                        # åŒæ—¶å°è¯•ä¸¤ç§è·¯å¾„æ ¼å¼ï¼ˆæ­£æ–œæ å’Œåæ–œæ ï¼‰
                        check_exprs = [
                            f"image_path == '{image_path}'",  # æ­£æ–œæ æ ¼å¼
                            f"image_path == '{image_path.replace('/', '\\\\')}'"  # åæ–œæ æ ¼å¼
                        ]
                        
                        for check_expr in check_exprs:
                            # ä½¿ç”¨ç›¸åŒçš„è¡¨è¾¾å¼åˆ é™¤å›¾ç‰‡
                            result = collection.delete(expr=check_expr)
                            if result.delete_count > 0:
                                print(f"   åˆ é™¤å›¾ç‰‡ {image_path} å¯¹åº”çš„å‘é‡ï¼Œåˆ é™¤è¡Œæ•°: {result.delete_count}")
                                successfully_deleted.add(image_path)
                                break
                        
                        # å¦‚æœæ²¡æœ‰ä½¿ç”¨ä»»ä½•è¡¨è¾¾å¼åˆ é™¤æˆåŠŸï¼Œå‡è®¾å›¾ç‰‡ä¸å­˜åœ¨
                        if image_path not in successfully_deleted:
                            successfully_deleted.add(image_path)
                    except Exception as delete_error:
                        print(f"   åˆ é™¤å›¾ç‰‡ {image_path} æ—¶å‡ºé”™: {delete_error}")
                        # å³ä½¿åˆ é™¤å¤±è´¥ï¼Œä¹Ÿä»existing_imagesä¸­ç§»é™¤ï¼Œé¿å…ä¸‹æ¬¡é‡å¤å°è¯•
                        successfully_deleted.add(image_path)
                
                # åˆ·æ–°é›†åˆï¼Œç¡®ä¿åˆ é™¤æ“ä½œç”Ÿæ•ˆ
                collection.flush()
                
                # æ›´æ–°existing_imagesé›†åˆï¼Œç§»é™¤å·²æˆåŠŸåˆ é™¤çš„å›¾ç‰‡
                existing_images -= successfully_deleted
                
                # é‡Šæ”¾é›†åˆèµ„æº
                collection.release()
            else:
                print(f"   æ•°æ®åº“ä¸æœ¬åœ°å›¾ç‰‡ä¸€è‡´ï¼Œæ— éœ€åˆ é™¤æ“ä½œ")
        except Exception as e:
            print(f"   åŒæ­¥æ•°æ®åº“ä¸æœ¬åœ°å›¾ç‰‡å¤±è´¥: {e}")
    
    # è¿‡æ»¤å‡ºéœ€è¦å¤„ç†çš„æ–°å›¾ç‰‡
    candidate_images = []
    for image_path in all_candidate_images:
        rel_path = os.path.relpath(image_path, candidate_dir)
        # å½’ä¸€åŒ–è·¯å¾„æ ¼å¼ï¼Œç¡®ä¿è·¨å¹³å°ä¸€è‡´æ€§
        normalized_rel_path = rel_path.replace('\\', '/')
        if normalized_rel_path not in existing_images:
            candidate_images.append(image_path)
    
    if not candidate_images:
        print(f"âœ… æ‰€æœ‰å›¾ç‰‡ç‰¹å¾å·²å­˜åœ¨ï¼Œæ— éœ€æ›´æ–°")
        return True
    
    print(f"   éœ€è¦å¤„ç† {len(candidate_images)} å¼ æ–°å›¾ç‰‡")
    
    # 5. æ‰¹é‡æ’å…¥å›¾ç‰‡ç‰¹å¾
    print(f"\nğŸ’¾ å¼€å§‹æ‰¹é‡æ’å…¥å›¾ç‰‡ç‰¹å¾...")
    
    try:
        # æå–æ‰€æœ‰å›¾ç‰‡çš„ç‰¹å¾ï¼Œä½¿ç”¨æ‰¹é‡å¤„ç†
        print(f"   ä½¿ç”¨æ‰¹é‡å¤„ç†è¿›è¡Œç‰¹å¾æå–ï¼Œæ‰¹é‡å¤§å°: {batch_size}")
        features_dict = feature_extractor.extract_batch_features(
            candidate_images,
            show_progress=True,
            base_dir=candidate_dir,
            batch_size=batch_size
        )
        
        # ç»Ÿè®¡æˆåŠŸå’Œå¤±è´¥çš„æ•°é‡
        success_count = len(features_dict)
        error_count = len(candidate_images) - success_count
    
        # æ‰¹é‡æ’å…¥ç‰¹å¾åˆ°å‘é‡æ•°æ®åº“
        if features_dict:
            # åˆ†æ‰¹æ’å…¥ç‰¹å¾
            batch_size = 128
            features_list = list(features_dict.values())
            image_paths_list = list(features_dict.keys())
            
            for i in range(0, len(features_list), batch_size):
                batch_features = features_list[i:i + batch_size]
                batch_paths = image_paths_list[i:i + batch_size]
                
                # å¯¹ç‰¹å¾è¿›è¡ŒL2å½’ä¸€åŒ–å¤„ç†ï¼ˆç”¨äºä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
                normalized_batch_features = []
                for feature in batch_features:
                    norm = np.linalg.norm(feature)
                    if norm > 0:
                        normalized_feature = feature / norm
                    else:
                        normalized_feature = feature
                    normalized_batch_features.append(normalized_feature)
                
                # æ’å…¥åˆ°å‘é‡æ•°æ®åº“
                vector_db.insert_features(normalized_batch_features, batch_paths, batch_paths)
                
                print(f"   æ’å…¥æ‰¹æ¬¡ {i//batch_size + 1}/{(len(features_list) + batch_size - 1)//batch_size} å®Œæˆ")
        
        print(f"âœ… ç‰¹å¾æå–å®Œæˆ!")
        print(f"   æˆåŠŸ: {success_count} å¼ å›¾ç‰‡")
        print(f"   å¤±è´¥: {error_count} å¼ å›¾ç‰‡")
        
        if success_count > 0:
            print(f"\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
            try:
                stats = vector_db.get_collection_stats()
                print(f"   é›†åˆåç§°: {stats.get('collection_name', 'N/A')}")
                print(f"   å‘é‡æ•°é‡: {stats.get('num_entities', 0)}")
                print(f"   å‘é‡ç»´åº¦: {stats.get('dimension', 0)}")
            except Exception as e:
                print(f"âš  æ— æ³•è·å–ç»Ÿè®¡ä¿¡æ¯: {e}")
        
        return success_count > 0
    
    except Exception as e:
        print(f"âŒ ç‰¹å¾æå–å¤±è´¥: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description='è¯„ä¼°å›¾åƒç›¸ä¼¼åº¦æ¨¡å‹')
    parser.add_argument('--model', type=str, required=True, help='è¦è¯„ä¼°çš„æ¨¡å‹åç§°')
    parser.add_argument('--annotations', type=str, default='similarity_annotations.json', help='æ ‡æ³¨æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--image_dir', type=str, default='querySet', help='æŸ¥è¯¢é›†å›¾åƒç›®å½•è·¯å¾„')
    parser.add_argument('--device', type=str, default='cpu', help='è¿è¡Œè®¾å¤‡ (auto, cpu, cuda, mps)')
    parser.add_argument('--extract_candidates', type=str, help='å€™é€‰é›†å›¾ç‰‡ç›®å½•è·¯å¾„ï¼ˆå¦‚æœæä¾›ï¼Œåˆ™åªæå–ç‰¹å¾ä¸è¿›è¡Œè¯„ä¼°ï¼‰')
    parser.add_argument('--overwrite', action='store_true', help='æ˜¯å¦è¦†ç›–ç°æœ‰é›†åˆï¼ˆTrue: åˆ é™¤ç°æœ‰é›†åˆå¹¶é‡æ–°åˆ›å»º, False: å¢é‡æ›´æ–°ï¼‰')
    parser.add_argument('--batch_size', type=int, default=8, help='æ‰¹é‡å¤„ç†å¤§å°ï¼ˆé»˜è®¤: 8ï¼‰')
    parser.add_argument('--refresh', action='store_true', help='æ˜¯å¦åˆ·æ–°ç‰¹å¾ï¼ˆTrue: æ£€æŸ¥å¹¶æ›´æ–°æ–°å›¾ç‰‡çš„ç‰¹å¾, False: ä¸æ‰§è¡Œä»»ä½•æ“ä½œï¼‰')
    """
    python evaluate_model.py --model resnet50 --extract_candidates img --refresh
    pyton evaluate_model.py --model resnet50 
    """
    
    args = parser.parse_args()
    
    # å¦‚æœæŒ‡å®šäº†å€™é€‰é›†ç›®å½•ï¼Œåˆ™åªæå–ç‰¹å¾
    if args.extract_candidates:
        success = extract_candidate_features(
            model_name=args.model,
            candidate_dir=args.extract_candidates,
            device=args.device,
            overwrite=args.overwrite,
            batch_size=args.batch_size,
            refresh=args.refresh
        )
        if success:
            print("\nâœ… å€™é€‰é›†ç‰¹å¾æå–å®Œæˆ!")
        else:
            print("\nâŒ å€™é€‰é›†ç‰¹å¾æå–å¤±è´¥!")
            
        return
    
    # éªŒè¯è¾“å…¥è·¯å¾„
    if not os.path.exists(args.annotations):
        print(f"âŒ æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {args.annotations}")
        return
    
    if not os.path.exists(args.image_dir):
        print(f"âŒ å›¾åƒç›®å½•ä¸å­˜åœ¨: {args.image_dir}")
        return
    
    # æ‰§è¡Œè¯„ä¼°
    results = evaluate_model(
        model_name=args.model,
        annotations_path=args.annotations,
        image_dir=args.image_dir,
        device=args.device
    )
    
    if results:
        print("\nâœ… è¯„ä¼°å®Œæˆ!")
    else:
        print("\nâŒ è¯„ä¼°å¤±è´¥!")

if __name__ == "__main__":
    main() 