# æ¨¡å‹ç¼“å­˜ç®¡ç†å™¨
import os
import ssl
from pathlib import Path
import torch
import warnings
warnings.filterwarnings('ignore')

# ========== SSLè¯ä¹¦ä¿®å¤ ==========
ssl._create_default_https_context = ssl._create_unverified_context

class ModelCacheManager:
    """æ¨¡å‹ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir="./models/cache"):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        
        å‚æ•°:
            cache_dir: ç¼“å­˜ç›®å½•è·¯å¾„
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
        # è®¾ç½®PyTorchç¼“å­˜ç¯å¢ƒå˜é‡
        os.environ['TORCH_HOME'] = str(self.cache_dir)
        
        # æ¨¡å‹æ–‡ä»¶æ˜ å°„
        self.model_files = {
            'resnet50': 'resnet50-11ad3fa6.pth',
            'efficientnet_lite0': 'efficientnet_lite0-0aa5c2b1.pth',
            'mobilenet_v3_small': 'mobilenet_v3_small-047dcff4.pth',
            'convnext_tiny': 'convnext_tiny-983f1584.pth',
            'openclip_vit_b_32': 'open_clip_model.safetensors',
            'openclip_vit_l_14': 'open_clip_model_vit_l_14.safetensors',
            'dinov2_vit_s': 'dinov2_vit_small.pth',
        }
        
        # æ¨¡å‹åŠ è½½å‡½æ•°æ˜ å°„
        self.model_loaders = {
            'resnet50': self._load_resnet50,
            'efficientnet_lite0': self._load_efficientnet_lite0,
            'mobilenet_v3_small': self._load_mobilenet_v3_small,
            'convnext_tiny': self._load_convnext_tiny,
            'openclip_vit_b_32': self._load_openclip_vit_b_32,
            'openclip_vit_l_14': self._load_openclip_vit_l_14,
            'dinov2_vit_s': self._load_dinov2_vit_s,
        }
        
        print(f"ğŸ“ æ¨¡å‹ç¼“å­˜ç›®å½•: {self.cache_dir.absolute()}")
    
    def get_model_path(self, model_name):
        """è·å–æ¨¡å‹æ–‡ä»¶è·¯å¾„"""
        if model_name not in self.model_files:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")
        return self.cache_dir / self.model_files[model_name]
    
    def is_model_cached(self, model_name):
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ç¼“å­˜"""
        model_path = self.get_model_path(model_name)
        return model_path.exists()
    
    def load_model_from_cache(self, model_name):
        """
        ä»ç¼“å­˜åŠ è½½æ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä¸‹è½½
        
        å‚æ•°:
            model_name: æ¨¡å‹åç§°
            
        è¿”å›:
            model: åŠ è½½çš„æ¨¡å‹
        """
        if model_name not in self.model_loaders:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")
        
        # æ£€æŸ¥ç¼“å­˜
        if self.is_model_cached(model_name):
            print(f"âœ… ä»ç¼“å­˜åŠ è½½: {model_name}")
            try:
                # å°è¯•ä»ç¼“å­˜åŠ è½½
                return self.model_loaders[model_name]()
            except:
                # å¦‚æœç¼“å­˜æ–‡ä»¶æŸåï¼Œåˆ é™¤å¹¶é‡æ–°ä¸‹è½½
                model_path = self.get_model_path(model_name)
                print(f"âš  ç¼“å­˜æ–‡ä»¶æŸåï¼Œåˆ é™¤: {model_path}")
                model_path.unlink(missing_ok=True)
        
        # ä¸‹è½½æ¨¡å‹
        print(f"ğŸ“¥ ä¸‹è½½æ¨¡å‹: {model_name}")
        try:
            model = self.model_loaders[model_name]()
            print(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_name}")
            return model
        except Exception as e:
            print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
            raise
    
    def _load_resnet50(self):
        """åŠ è½½ResNet50æ¨¡å‹"""
        from torchvision import models
        return models.resnet50(pretrained=True)
    
    def _load_efficientnet_lite0(self):
        """
        åŠ è½½EfficientNet-B0æ¨¡å‹ï¼ˆæ›¿ä»£EfficientNet-Lite0ï¼‰
        """
        try:
            from efficientnet_pytorch import EfficientNet
            model = EfficientNet.from_pretrained('efficientnet-b0')
            return model
        except ImportError:
            print("âŒ éœ€è¦å®‰è£… efficientnet-pytorch åŒ…")
            print("è¯·è¿è¡Œ: pip install efficientnet-pytorch")
            raise
    
    def _load_mobilenet_v3_small(self):
        """åŠ è½½MobileNetV3-Smallæ¨¡å‹"""
        from torchvision import models
        return models.mobilenet_v3_small(pretrained=True)
    
    def _load_convnext_tiny(self):
        """åŠ è½½ConvNeXt-Tinyæ¨¡å‹"""
        from torchvision import models
        return models.convnext_tiny(pretrained=True)
    
    def _load_openclip_vit_b_32(self):
        """
        åŠ è½½OpenCLIP ViT-B/32æ¨¡å‹
        """
        try:
            import open_clip
            import os
            from pathlib import Path
            
            # è®¾ç½®ç¦»çº¿æ¨¡å¼ç¯å¢ƒå˜é‡
            os.environ['HF_HUB_OFFLINE'] = '1'
            os.environ['TRANSFORMERS_OFFLINE'] = '1'
            
            # æ„å»ºæœ¬åœ°æ¨¡å‹æ–‡ä»¶è·¯å¾„
            local_model_path = Path(self.cache_dir) / "timm" / "vit_base_patch32_clip_224.laion2b_e16" / "open_clip_model.safetensors"
            
            if local_model_path.exists():
                # å¦‚æœæœ¬åœ°æœ‰æ¨¡å‹æ–‡ä»¶ï¼Œç›´æ¥åŠ è½½
                model, _, preprocess = open_clip.create_model_and_transforms(
                    'ViT-B-32', 
                    pretrained=str(local_model_path)
                )
                print(f"âœ… ä»æœ¬åœ°æ–‡ä»¶åŠ è½½ OpenCLIP æ¨¡å‹: {local_model_path}")
            else:
                # å¦åˆ™ä»ç½‘ç»œä¸‹è½½
                print("âš ï¸ æœ¬åœ°æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä»ç½‘ç»œåŠ è½½...")
                model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_e16')
            
            # æ›´æ–°å®ä¾‹çš„é¢„å¤„ç†æ–¹æ³•ï¼Œå› ä¸ºCLIPæœ‰è‡ªå·±çš„é¢„å¤„ç†
            self.clip_preprocess = preprocess
            return model
        except ImportError:
            print("âŒ éœ€è¦å®‰è£… open_clip åŒ…")
            print("è¯·è¿è¡Œ: pip install open_clip_torch")
            raise
        except Exception as e:
            print(f"âŒ OpenCLIPæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("è¯·ç¡®ä¿å·²å®‰è£… open_clip_torch åŒ…å¹¶ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨")
            raise
    
    def _load_openclip_vit_l_14(self):
        """
        åŠ è½½OpenCLIP ViT-L/14æ¨¡å‹
        """
        try:
            import open_clip
            import os
            import torch
            from pathlib import Path
            
            # æ„å»ºæœ¬åœ°æ¨¡å‹æ–‡ä»¶è·¯å¾„
            openclip_model_paths = [
                Path(self.cache_dir) / "open_clip_pytorch_model.safetensors",
                Path(self.cache_dir) / "open_clip_pytorch_model.bin",
                Path(self.cache_dir) / "model.safetensors",
                Path(self.cache_dir) / "pytorch_model.bin",
                Path(self.cache_dir) / "open_clip_model_vit_l_14.safetensors"
            ]
            
            # æ£€æŸ¥ç”¨æˆ·æä¾›çš„æ¨¡å‹æ–‡ä»¶è·¯å¾„
            user_model_path = Path(self.cache_dir) / "vit_l_14-laion2b_s32b_b82k.bin"
            
            # åŒæ—¶æ£€æŸ¥å­ç›®å½•ä¸­çš„æ¨¡å‹æ–‡ä»¶ï¼ˆå…¼å®¹æ—§è·¯å¾„ï¼‰
            local_model_dir = Path(self.cache_dir) / "timm" / "vit_large_patch14_clip_224.laion2b_e16"
            local_model_path_subdir = local_model_dir / "open_clip_model_vit_l_14.safetensors"
            
            # ç¡®ä¿æœ¬åœ°æ¨¡å‹ç›®å½•å­˜åœ¨
            local_model_dir.mkdir(parents=True, exist_ok=True)
            
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆæŒ‰ä¼˜å…ˆçº§é¡ºåºï¼‰
            model_path_to_use = None
            # æ£€æŸ¥ç”¨æˆ·æä¾›çš„è·¯å¾„
            if user_model_path.exists():
                model_path_to_use = user_model_path
                print(f"âœ… æ‰¾åˆ°ç”¨æˆ·æä¾›çš„æ¨¡å‹æ–‡ä»¶: {model_path_to_use}")
            # æ£€æŸ¥model_cacheç›®å½•ä¸­çš„OpenCLIPæ¨¡å‹æ–‡ä»¶
            else:
                for path in openclip_model_paths:
                    if path.exists():
                        model_path_to_use = path
                        print(f"âœ… æ‰¾åˆ°æœ¬åœ°OpenCLIPæ¨¡å‹æ–‡ä»¶: {model_path_to_use}")
                        break
            # æ£€æŸ¥å­ç›®å½•ä¸­çš„æ¨¡å‹æ–‡ä»¶
            if not model_path_to_use and local_model_path_subdir.exists():
                model_path_to_use = local_model_path_subdir
                print(f"âœ… æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path_to_use}")
            
            if model_path_to_use:
                # å¦‚æœæœ¬åœ°æœ‰æ¨¡å‹æ–‡ä»¶ï¼Œç›´æ¥åŠ è½½
                try:
                    # è®¾ç½®ç¦»çº¿æ¨¡å¼ç¯å¢ƒå˜é‡
                    os.environ['HF_HUB_OFFLINE'] = '1'
                    os.environ['TRANSFORMERS_OFFLINE'] = '1'
                    
                    model, _, preprocess = open_clip.create_model_and_transforms(
                        'ViT-L-14', 
                        pretrained=str(model_path_to_use)
                    )
                    print(f"âœ… ä»æœ¬åœ°æ–‡ä»¶åŠ è½½ OpenCLIP ViT-L/14 æ¨¡å‹: {model_path_to_use}")
                except Exception as e:
                    print(f"âš ï¸ ä»æœ¬åœ°æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
                    print("âš ï¸ å°è¯•ä½¿ç”¨é»˜è®¤çš„CLIPæ¨¡å‹...")
                    # å°è¯•ä½¿ç”¨é»˜è®¤çš„CLIPæ¨¡å‹ï¼Œä¸æŒ‡å®špretrained
                    model, _, preprocess = open_clip.create_model_and_transforms('ViT-L-14')
            else:
                # å¦åˆ™ä»ç½‘ç»œä¸‹è½½
                print("âš ï¸ æœ¬åœ°æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä»ç½‘ç»œåŠ è½½...")
                try:
                    # å°è¯•ä½¿ç”¨laion2b_s32b_b82kæƒé‡
                    model, _, preprocess = open_clip.create_model_and_transforms('ViT-L-14', pretrained='laion2b_s32b_b82k')
                except Exception as e:
                    print(f"âš ï¸ ä»ç½‘ç»œåŠ è½½å¤±è´¥: {e}")
                    print("âš ï¸ å°è¯•ä½¿ç”¨é»˜è®¤çš„CLIPæ¨¡å‹...")
                    # å°è¯•ä½¿ç”¨é»˜è®¤çš„CLIPæ¨¡å‹ï¼Œä¸æŒ‡å®špretrained
                    model, _, preprocess = open_clip.create_model_and_transforms('ViT-L-14')
            
            # æ›´æ–°å®ä¾‹çš„é¢„å¤„ç†æ–¹æ³•ï¼Œå› ä¸ºCLIPæœ‰è‡ªå·±çš„é¢„å¤„ç†
            self.clip_preprocess = preprocess
            return model
        except ImportError:
            print("âŒ éœ€è¦å®‰è£… open_clip åŒ…")
            print("è¯·è¿è¡Œ: pip install open_clip_torch")
            raise
        except Exception as e:
            print(f"âŒ OpenCLIP ViT-L/14 æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("è¯·ç¡®ä¿å·²å®‰è£… open_clip_torch åŒ…å¹¶ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸")
            raise
    
    def _load_dinov2_vit_s(self):
        """
        åŠ è½½DINOv2 ViT-Sæ¨¡å‹
        """
        try:
            import torch
            import torchvision.models as models
            
            # å°è¯•åŠ è½½DINOv2 ViT-Sæ¨¡å‹
            model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')
            print("âœ… DINOv2 ViT-Sæ¨¡å‹åŠ è½½æˆåŠŸ")
            return model
        except ImportError as e:
            print("âŒ å¯¼å…¥é”™è¯¯ï¼Œå¯èƒ½éœ€è¦å®‰è£…ç›¸å…³ä¾èµ–")
            print(f"é”™è¯¯: {e}")
            print("è¯·ç¡®ä¿å·²å®‰è£… torch å’Œ torchvision")
            raise
        except Exception as e:
            print(f"âŒ DINOv2æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("è¯·ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸ï¼Œæˆ–å·²åœ¨æœ¬åœ°ç¼“å­˜æ¨¡å‹")
            raise
    
    def get_cached_models(self):
        """è·å–å·²ç¼“å­˜çš„æ¨¡å‹åˆ—è¡¨"""
        cached_models = []
        for model_name, filename in self.model_files.items():
            if (self.cache_dir / filename).exists():
                cached_models.append(model_name)
        return cached_models
    
    def clear_cache(self, model_name=None):
        """æ¸…ç†ç¼“å­˜"""
        if model_name:
            # æ¸…ç†æŒ‡å®šæ¨¡å‹
            model_path = self.get_model_path(model_name)
            if model_path.exists():
                model_path.unlink()
                print(f"ğŸ—‘ å·²åˆ é™¤ç¼“å­˜: {model_name}")
        else:
            # æ¸…ç†æ‰€æœ‰ç¼“å­˜
            for file in self.cache_dir.glob("*.pth"):
                file.unlink()
            print(f"ğŸ—‘ å·²æ¸…ç†æ‰€æœ‰ç¼“å­˜")
