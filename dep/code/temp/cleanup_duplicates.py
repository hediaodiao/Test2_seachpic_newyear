#!/usr/bin/env python3
"""
æ¸…ç†Milvusæ•°æ®åº“ä¸­çš„é‡å¤è®°å½•
"""

from pymilvus import connections, Collection, utility
import logging

# è®¾ç½®æ—¥å¿—çº§åˆ«
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def cleanup_duplicate_records(collection_name):
    """
    æ¸…ç†æŒ‡å®šé›†åˆä¸­çš„é‡å¤è®°å½•
    
    å‚æ•°:
        collection_name: é›†åˆåç§°
    """
    print(f"\n{'='*60}")
    print(f"ğŸ§¹ å¼€å§‹æ¸…ç†é›†åˆ {collection_name} ä¸­çš„é‡å¤è®°å½•")
    print(f"{'='*60}")
    
    # è¿æ¥åˆ°MilvusæœåŠ¡å™¨
    print("è¿æ¥åˆ°MilvusæœåŠ¡å™¨...")
    connections.connect(host='localhost', port=19531)
    
    # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
    if not utility.has_collection(collection_name):
        print(f"âŒ é›†åˆ {collection_name} ä¸å­˜åœ¨")
        return False
    
    # è·å–é›†åˆ
    collection = Collection(collection_name)
    print(f"âœ… é›†åˆåŠ è½½æˆåŠŸ: {collection_name}")
    
    # åŠ è½½é›†åˆ
    collection.load()
    
    # è·å–é›†åˆä¸­çš„å®ä½“æ•°é‡
    collection.flush()
    total_entities = collection.num_entities
    print(f"ğŸ“Š æ¸…ç†å‰é›†åˆä¸­çš„å®ä½“æ•°é‡: {total_entities}")
    
    # æŸ¥è¯¢æ‰€æœ‰å›¾ç‰‡è·¯å¾„
    print("æŸ¥è¯¢æ‰€æœ‰å›¾ç‰‡è·¯å¾„...")
    result = collection.query(expr='id >= 0', output_fields=['id', 'image_path'])
    print(f"âœ… æŸ¥è¯¢åˆ° {len(result)} æ¡è®°å½•")
    
    # æ‰¾å‡ºé‡å¤çš„å›¾ç‰‡è·¯å¾„
    print("æ‰¾å‡ºé‡å¤çš„å›¾ç‰‡è·¯å¾„...")
    path_to_ids = {}
    duplicate_paths = set()
    
    for item in result:
        image_path = item['image_path']
        image_id = item['id']
        
        if image_path not in path_to_ids:
            path_to_ids[image_path] = []
        path_to_ids[image_path].append(image_id)
        
        if len(path_to_ids[image_path]) > 1:
            duplicate_paths.add(image_path)
    
    print(f"ğŸ“‹ æ‰¾åˆ° {len(duplicate_paths)} ä¸ªé‡å¤çš„å›¾ç‰‡è·¯å¾„")
    
    # åˆ é™¤é‡å¤è®°å½•ï¼Œä¿ç•™æ¯ä¸ªå›¾ç‰‡è·¯å¾„çš„ç¬¬ä¸€ä¸ªè®°å½•
    deleted_count = 0
    for path in duplicate_paths:
        ids = path_to_ids[path]
        # ä¿ç•™ç¬¬ä¸€ä¸ªè®°å½•ï¼Œåˆ é™¤å…¶ä»–è®°å½•
        ids_to_delete = ids[1:]
        
        if ids_to_delete:
            print(f"ğŸ”„ æ¸…ç†å›¾ç‰‡ {path} çš„é‡å¤è®°å½•...")
            print(f"   å›¾ç‰‡ {path} æœ‰ {len(ids)} ä¸ªé‡å¤è®°å½•ï¼Œä¿ç•™ID: {ids[0]}, åˆ é™¤ID: {ids_to_delete}")
            
            # é€ä¸ªåˆ é™¤é‡å¤è®°å½•
            for image_id in ids_to_delete:
                expr = f"id == {image_id}"
                delete_result = collection.delete(expr=expr)
                deleted_count += delete_result.delete_count
                
                if delete_result.delete_count > 0:
                    print(f"   âœ… æˆåŠŸåˆ é™¤ID: {image_id}")
                else:
                    print(f"   âŒ åˆ é™¤ID: {image_id} å¤±è´¥")
    
    # åˆ·æ–°é›†åˆï¼Œç¡®ä¿åˆ é™¤æ“ä½œç”Ÿæ•ˆ
    collection.flush()
    
    # é‡Šæ”¾é›†åˆèµ„æº
    collection.release()
    
    # è·å–æ¸…ç†åçš„å®ä½“æ•°é‡
    collection.load()
    collection.flush()
    final_entities = collection.num_entities
    collection.release()
    
    print(f"\n{'='*60}")
    print(f"ğŸ§¹ æ¸…ç†å®Œæˆ")
    print(f"{'='*60}")
    print(f"ğŸ“Š æ¸…ç†å‰å®ä½“æ•°é‡: {total_entities}")
    print(f"ğŸ“Š æ¸…ç†åå®ä½“æ•°é‡: {final_entities}")
    print(f"ğŸ—‘ï¸  å…±åˆ é™¤ {deleted_count} æ¡é‡å¤è®°å½•")
    print(f"ğŸ“ˆ å‡å°‘äº† {total_entities - final_entities} æ¡è®°å½•")
    
    return True

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='æ¸…ç†Milvusæ•°æ®åº“ä¸­çš„é‡å¤è®°å½•')
    parser.add_argument('--model', type=str, default='resnet50', help='æ¨¡å‹åç§°')
    parser.add_argument('--collection', type=str, help='é›†åˆåç§°ï¼ˆå¦‚æœæä¾›ï¼Œåˆ™å¿½ç•¥modelå‚æ•°ï¼‰')
    
    args = parser.parse_args()
    
    if args.collection:
        collection_name = args.collection
    else:
        collection_name = f"image_features_{args.model}"
    
    cleanup_duplicate_records(collection_name)
